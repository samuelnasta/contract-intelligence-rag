# Contract Intelligence RAG - Project Documentation

## ğŸ“‹ Overview

**Contract Intelligence RAG** is an End-to-End Retrieval-Augmented Generation (RAG) pipeline designed for high-precision legal and technical document analysis. Built with production-grade Data Engineering principles, this system enables intelligent querying and analysis of contract documents through advanced natural language processing and semantic search capabilities.

### Key Features
- ğŸ“„ **PDF Document Processing**: Automated extraction and processing of legal documents
- ğŸ” **Vector-Based Semantic Search**: Leverages embeddings for precise document retrieval
- ğŸ¤– **LLM Integration**: Uses Groq and HuggingFace models for intelligent query responses
- ğŸ“Š **Multi-Database Architecture**: PostgreSQL for metadata, ChromaDB for vector storage
- ğŸ³ **Docker Containerization**: Full containerized deployment with docker-compose
- ğŸ” **Production-Ready**: Comprehensive error handling, logging, and testing framework

---

## ğŸ—ï¸ Project Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Application Layer                       â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   App.py     â”‚  â”‚  QueryEngine â”‚  â”‚  Document   â”‚       â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚  Ingestor   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                  â”‚                   â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚         Data Layer                   â”‚              â”‚
â”‚         â”‚                                      â”‚              â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”‚
â”‚    â”‚ DatabaseManager â”‚          â”‚ Vector Storage      â”‚      â”‚
â”‚    â”‚  (PostgreSQL)   â”‚          â”‚  (ChromaDB)         â”‚      â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Project Structure

```
contract-intelligence-rag/
â”œâ”€â”€ src/                              # Main application source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ App.py                        # Main application orchestrator
â”‚   â”œâ”€â”€ DocumentIngestor.py           # PDF processing & embedding
â”‚   â”œâ”€â”€ DatabaseManager.py            # PostgreSQL operations
â”‚   â”œâ”€â”€ QueryEngine.py                # RAG query interface
â”‚   â”œâ”€â”€ ApiCommunication.py           # API communication utilities
â”‚   â”œâ”€â”€ Logger.py                     # Logging configuration
â”‚   â”œâ”€â”€ TextUtils.py                  # Text processing utilities
â”‚   â”œâ”€â”€ exceptions/                   # Custom exception classes
â”‚   â”‚   â”œâ”€â”€ BaseProjectException.py
â”‚   â”‚   â”œâ”€â”€ DatabaseManagerException.py
â”‚   â”‚   â”œâ”€â”€ DocumentIngestorException.py
â”‚   â”‚   â”œâ”€â”€ QueryEngineException.py
â”‚   â”‚   â”œâ”€â”€ UtilsException.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ tests/                            # Test suite
â”‚   â”œâ”€â”€ conftest.py                   # Pytest configuration
â”‚   â”œâ”€â”€ test_app.py
â”‚   â”œâ”€â”€ test_database_manager.py
â”‚   â”œâ”€â”€ test_document_ingestor.py
â”‚   â”œâ”€â”€ test_query_engine.py
â”‚   â”œâ”€â”€ test_text_utils.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ data/                             # Data directory
â”‚   â”œâ”€â”€ raw/                          # Raw PDF files for ingestion
â”‚   â””â”€â”€ processed/                    # Processed data output
â”‚       â”œâ”€â”€ exhibit10.json
â”‚       â”œâ”€â”€ Hacienda.json
â”‚       â””â”€â”€ l86560aex10-ffpdf.json
â”‚
â”œâ”€â”€ chroma/                           # Vector database storage
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ chroma.sqlite3
â”‚       â””â”€â”€ collection directories/
â”‚
â”œâ”€â”€ logs/                             # Application logs
â”‚
â”œâ”€â”€ docker-compose.yml                # Docker services configuration
â”œâ”€â”€ requirements.txt                  # Python dependencies
â””â”€â”€ README.md                         # Project overview
```

---

## ğŸ”§ Core Modules

### 1. **App.py** - Main Application Orchestrator
Main entry point for the RAG pipeline.

**Key Methods:**
- `__init__(raw_data_dir, db_path)` - Initialize application configuration
- `get_pdf_files()` - Retrieve PDF files from raw data directory
- Document pipeline orchestration

**Responsibilities:**
- Coordinate document ingestion workflow
- Manage data flow between components
- Handle application-level exceptions

---

### 2. **DocumentIngestor.py** - Document Processing
Handles PDF reading, chunking, and embedding generation.

**Key Methods:**
- `__init__(file_path, db_path)` - Initialize with PDF file
- PDF loading and text extraction
- Text splitting with configurable chunk size
- Embedding generation using HuggingFace models
- Vector storage in ChromaDB
- Metadata tracking and saving

**Exceptions:**
- `DocumentLoadingException` - PDF loading failures
- `DocumentSplittingException` - Text chunking errors
- `VectorStorageException` - Embedding storage failures
- `SaveDataException` - Metadata saving errors

---

### 3. **DatabaseManager.py** - PostgreSQL Management
Manages relational database operations for tracking and metadata.

**Key Methods:**
- `__init__()` - Initialize database connection
- `_get_connection()` - Establish database connection
- Document ingestion registration
- Ingestion status tracking
- Table creation and maintenance

**Exceptions:**
- `DatabaseConnectionException` - Connection failures
- `IngestionRegistrationException` - Registration errors
- `IngestionStatusUpdateException` - Status update failures

**Database Configuration:**
```
Host: localhost (docker container)
Port: 5432
Database: contract_rag
User: ${POSTGRES_USER}
Password: ${POSTGRES_PASSWORD}
```

---

### 4. **QueryEngine.py** - RAG Query Interface
Handles document retrieval and LLM-based query responses.

**Key Methods:**
- `__init__(chroma_host, chroma_port)` - Initialize ChromaDB connection
- Document similarity search
- RAG query processing
- Response generation using Groq LLM

**Components:**
- **Embeddings**: HuggingFace `all-MiniLM-L6-v2`
- **LLM**: Groq API (temperature: 0)
- **Vector DB**: ChromaDB (host: localhost, port: 8001)

**Exceptions:**
- `DBConnectionException` - Database connection issues
- `DocumentRetrieveException` - Retrieval failures
- `ModelResponseException` - LLM response errors
- `RAGQueryException` - General query errors

---

### 5. **Supporting Modules**

#### Logger.py
- Centralized logging configuration
- Log output to file and console
- Structured error tracking

#### TextUtils.py
- Text preprocessing utilities
- String normalization
- Text cleaning and validation

#### ApiCommunication.py
- API endpoint communication
- Request/response handling
- Error management for external APIs

---

## ğŸ—„ï¸ Database Architecture

### PostgreSQL (Metadata Storage)
Tracks document ingestion history and metadata.

**Key Tables:**
- Document metadata
- Ingestion records
- Processing status tracking

**Connection Details:**
- Docker Container: `contract-postgres`
- Port: 5432
- Admin Tool: Adminer (port 8080)

### ChromaDB (Vector Storage)
Stores document embeddings for semantic search.

**Configuration:**
- Docker Container: `contract-chromadb`
- Port: 8001
- Persistence: `/chroma/data`
- Embedding Model: `all-MiniLM-L6-v2`

**Data Structure:**
- Collections organized by document type
- Metadata attached to each embedding
- Efficient similarity search

---

## ğŸ”„ Data Pipeline

### Ingestion Workflow
```
1. Load PDF File
   â””â”€> PyPDFLoader extracts text
   
2. Text Processing
   â””â”€> RecursiveCharacterTextSplitter chunks text
   
3. Embedding Generation
   â””â”€> HuggingFace model creates embeddings
   
4. Vector Storage
   â””â”€> Store in ChromaDB with metadata
   
5. Metadata Tracking
   â””â”€> Record in PostgreSQL
```

### Query Workflow
```
1. User Query
   â””â”€> Embed query using same model
   
2. Semantic Search
   â””â”€> Find similar documents in ChromaDB
   
3. Context Retrieval
   â””â”€> Gather relevant document chunks
   
4. LLM Response
   â””â”€> Groq generates answer with context
   
5. Return Response
   â””â”€> Present to user
```

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- Docker & Docker Compose
- Git

### Installation

1. **Clone Repository**
```bash
git clone <repository-url>
cd contract-intelligence-rag
```

2. **Set Environment Variables**
```bash
# Create .env file
echo "POSTGRES_USER=samuel" > .env
echo "POSTGRES_PASSWORD=your_password" >> .env
```

3. **Install Dependencies**
```bash
pip install -r requirements.txt
```

4. **Start Docker Services**
```bash
docker-compose up -d
```

5. **Verify Services**
```bash
# PostgreSQL: localhost:5432
# ChromaDB: localhost:8001
# Adminer: localhost:8080
```

### Running the Application

**Prerequisites:** * Linux Environment
* CPython 3.12.3
* Docker & Docker Compose installed

#### 1. Start Infrastructure
Before launching the API, you must start the vector database and metadata storage services:

```bash
# Start ChromaDB and PostgreSQL in the background
docker-compose up -d
```

Now we can slunch the app:
```bash
# Start the server on port 8000
uvicorn src.ApiCommunication:app --reload --host 0.0.0.0 --port 8000
```

#### Once the server is running, you can access the interactive documentation at Swagger UI: http://localhost:8000/docs

---

## ğŸ“¦ Dependencies

### Core Dependencies
| Package | Version | Purpose |
|---------|---------|---------|
| `langchain` | >=0.2.0 | LLM orchestration framework |
| `langchain-community` | >=0.2.0 | Community integrations |
| `langchain-groq` | >=0.1.3 | Groq LLM integration |
| `langchain-huggingface` | >=0.0.1 | HuggingFace embeddings |
| `chromadb` | 0.4.24 | Vector database |
| `psycopg2-binary` | 2.9.9 | PostgreSQL driver |

### Document Processing
| Package | Version | Purpose |
|---------|---------|---------|
| `pypdf` | 4.2.0 | PDF parsing |
| `unstructured[pdf]` | 0.13.2 | Document preprocessing |
| `sentence-transformers` | 2.7.0 | Embedding models |

### Backend & API
| Package | Version | Purpose |
|---------|---------|---------|
| `fastapi` | 0.110.1 | Web API framework |
| `uvicorn` | 0.29.0 | ASGI server |
| `python-dotenv` | 1.0.1 | Environment management |

### Development
| Package | Version | Purpose |
|---------|---------|---------|
| `pytest` | 9.0.2 | Testing framework |
| `pandas` | 2.2.2 | Data manipulation |
| `requests` | 2.31.0 | HTTP client |

---

## ğŸ§ª Testing

### Running Tests
```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_app.py

# Run with verbose output
pytest -v

# Run with coverage
pytest --cov=src
```

### Test Files
- `test_app.py` - Application orchestration tests
- `test_database_manager.py` - Database operations tests
- `test_document_ingestor.py` - Document ingestion tests
- `test_query_engine.py` - Query engine tests
- `test_text_utils.py` - Utility function tests

---

## ğŸ³ Docker Services

### docker-compose.yml Configuration

**Services:**
1. **PostgreSQL (contract-postgres)**
   - Image: `postgres:14-alpine`
   - Port: 5432
   - Volume: postgres_data
   - Health checks: Enabled

2. **ChromaDB (contract-chromadb)**
   - Image: `chromadb/chroma:latest`
   - Port: 8001 (mapped from 8000)
   - Persistence: `/chroma/data`
   - Backend: DuckDB+Parquet

3. **Adminer (contract-adminer)**
   - Image: `adminer:latest`
   - Port: 8080
   - Database UI for PostgreSQL

### Service Management
```bash
# Start all services
docker-compose up -d

# Stop all services
docker-compose down

# View logs
docker-compose logs -f

# Restart a specific service
docker-compose restart postgres
```

---

## âš ï¸ Error Handling

### Exception Hierarchy
```
BaseProjectException (root)
â”œâ”€â”€ DatabaseManagerException
â”‚   â”œâ”€â”€ DatabaseConnectionException
â”‚   â”œâ”€â”€ IngestionRegistrationException
â”‚   â”œâ”€â”€ IngestionStatusUpdateException
â”‚   â””â”€â”€ DatabaseTableCreationException
â”œâ”€â”€ DocumentIngestorException
â”‚   â”œâ”€â”€ DocumentLoadingException
â”‚   â”œâ”€â”€ DocumentSplittingException
â”‚   â”œâ”€â”€ VectorStorageException
â”‚   â””â”€â”€ SaveDataException
â”œâ”€â”€ QueryEngineException
â”‚   â”œâ”€â”€ DBConnectionException
â”‚   â”œâ”€â”€ DocumentRetrieveException
â”‚   â”œâ”€â”€ ModelResponseException
â”‚   â””â”€â”€ RAGQueryException
â””â”€â”€ UtilsException
    â””â”€â”€ Various text processing exceptions
```

### Logging
- **Logger**: Centralized via `Logger.py`
- **Output**: Console + File logs in `logs/` directory
- **Levels**: DEBUG, INFO, WARNING, ERROR, CRITICAL

---

## ğŸ” Configuration & Environment

### Environment Variables
```bash
POSTGRES_USER=<your_db_user>
POSTGRES_PASSWORD=<your_secure_password>
GROQ_API_KEY=<your_groq_api_key>
HUGGINGFACE_API_KEY=<optional>
```

### Configuration Points
- Raw data directory: `data/raw/`
- Vector DB path: `chroma/data/`
- Database credentials: Environment variables
- ChromaDB host/port: `localhost:8001`

---

## ğŸ“Š Data Flow Examples

### Example 1: Ingest a Legal Contract
```python
from src.DocumentIngestor import DocumentIngestor

# Initialize ingestor
ingestor = DocumentIngestor(
    file_path="data/raw/contract.pdf",
    db_path="chroma/data"
)

# Process document
# - Extract text
# - Split into chunks
# - Generate embeddings
# - Store in ChromaDB
# - Register in PostgreSQL
```

### Example 2: Query Documents with RAG
```python
from src.QueryEngine import QueryEngine

# Initialize query engine
engine = QueryEngine(chroma_host="localhost", chroma_port=8001)

# Perform semantic search
results = engine.query("What are the payment terms?")

# Returns:
# - Retrieved document chunks
# - LLM-generated answer with context
# - Confidence scores
```

---

## ğŸ“ˆ Performance Considerations

### Optimization Strategies
- **Chunking**: Tuned chunk size for optimal retrieval
- **Embeddings**: Lightweight model (`all-MiniLM-L6-v2`) for speed
- **Caching**: Metadata caching in PostgreSQL
- **Vector Search**: Efficient similarity search in ChromaDB

### Scalability
- Horizontal scaling with Docker Swarm or Kubernetes
- Load balancing for API endpoints
- Database connection pooling
- Batch processing for multiple documents

---

## ğŸ“„ License

This project is licensed under OSL-3.0.

---

## ğŸ‘¤ Author

Linkedin: [Samuel Valer Nasta](https://www.linkedin.com/in/samuelnasta/)
Repository: `/home/samuel/proyects/contract-intelligence-rag`

---

## ğŸ”— Additional Resources

- [LangChain Documentation](https://python.langchain.com/)
- [ChromaDB Docs](https://docs.trychroma.com/)
- [Groq API Reference](https://groq.com/docs/)
- [HuggingFace Embeddings](https://huggingface.co/models?library=sentence-transformers)

---

**Last Updated**: January 19, 2026  
**Status**: Production Ready
